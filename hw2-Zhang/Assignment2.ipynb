{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CS585 Assignment 2\n",
    "CS585 Image and Video Computing\n",
    "Lifu Zhang, Hin Lui Shum\n",
    "--------------\n",
    "This program introduces the following implementation\n",
    "\ta) Reading a stream of images from a webcamera, and displaying the video\n",
    "\tb) Skin color detection\n",
    "\tc) Hand gesture comparison\n",
    "\td) Graphical response upon detection\n",
    "--------------\n",
    "'''\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# templates for different hand gestures\n",
    "templates = []\n",
    "templates.append(cv2.imread('./yeah1.jpg', 0))\n",
    "templates.append(cv2.imread('./fist1.jpg', 0))\n",
    "templates.append(cv2.imread('./palm1.jpg', 0))\n",
    "templates.append(cv2.imread('./thumb1.jpg', 0))\n",
    "template_id = ['Scissors','Rock','Paper','Good']\n",
    "\n",
    "# colors for drawing rectangles\n",
    "color = [[255,0,0],[0,255,0],[255,255,0],[0,255,255]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that detects whether a saved hand gesture is detected\n",
    "# param binary The source binary image from skin detection\n",
    "# param binary The source color image from webcam\n",
    "\n",
    "def gesture_matching(binary, src):\n",
    "    image = binary\n",
    "    # loop through the available templates\n",
    "    for i in range(4):\n",
    "        w, h = templates[i].shape[::-1]\n",
    "        # Searching and finding the template in the binary screen\n",
    "        res = cv2.matchTemplate(image, templates[i], cv2.TM_CCOEFF_NORMED)\n",
    "        # setting threshold \n",
    "        threshold = 0.7\n",
    "        # finding location with the compare score higher than threshold\n",
    "        loc = np.where( res >= threshold)\n",
    "        max_val = 1\n",
    "        # draw rectangle and print text about the detected gesture accordingly\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            if max_val > threshold:\n",
    "                min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "                res[max_loc[1]-h//2:max_loc[1]+h//2+1, max_loc[0]-w//2:max_loc[0]+w//2+1] = 0   \n",
    "                cv2.rectangle(src,(max_loc[0],max_loc[1]), (max_loc[0]+w+1, max_loc[1]+h+1), color[i])\n",
    "                cv2.putText(src, str(template_id[i]), (max_loc[0]+w+1, max_loc[1]+h+1), \n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.0, (255,255,255))\n",
    "\n",
    "    return src\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that detects whether a pixel belongs to the skin based on RGB values\n",
    "# param src The source color image\n",
    "def my_skin_detect(src):\n",
    "    '''\n",
    "    Surveys of skin color modeling and detection techniques:\n",
    "    Vezhnevets, Vladimir, Vassili Sazonov, and Alla Andreeva. \"A survey on pixel-based skin color detection techniques.\" Proc. Graphicon. Vol. 3. 2003.\n",
    "    Kakumanu, Praveen, Sokratis Makrogiannis, and Nikolaos Bourbakis. \"A survey of skin-color modeling and detection methods.\" Pattern recognition 40.3 (2007): 1106-1122.\n",
    "    '''\n",
    "    dst = np.zeros(np.shape(src)[:-1], dtype=np.uint8)\n",
    "    \n",
    "    mask = np.logical_and.reduce((src[:,:,0] > 20, src[:,:,1] > 40, src[:,:,2] > 95, \n",
    "                                    src.max(axis=-1) - src.min(axis=-1) > 15, \n",
    "                                    abs(src[:,:,2] - src[:,:,1]) > 15, \n",
    "                                    src[:,:,2] > src[:,:,1], src[:,:,2] > src[:,:,0]))\n",
    "    dst[mask] = 255\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esc key is pressed by user\n"
     ]
    }
   ],
   "source": [
    "# ----------------\n",
    "# a) Reading a stream of images from a webcamera, and displaying the video\n",
    "# ----------------\n",
    "# For more information on reading and writing video: http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html\n",
    "# open the video camera no. 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# if not successful, exit program\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open the video cam\")\n",
    "    sys.exit()\n",
    "\n",
    "# create a window called \"Original\" for source webcam\n",
    "cv2.namedWindow(\"Original\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# read a new frame from video\n",
    "ret, frame0 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Cannot read a frame from video stream\")\n",
    "\n",
    "# show the frame in \"MyVideo\" window\n",
    "cv2.imshow(\"Original\", frame0)\n",
    "\n",
    "# create windows for skin detection and gesture detection\n",
    "cv2.namedWindow(\"Skin\", cv2.WINDOW_AUTOSIZE)\n",
    "cv2.namedWindow(\"Frame\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "len_history = 7\n",
    "my_motion_history = []\n",
    "fMH1 = np.zeros(np.shape(frame0)[:-1], dtype=np.uint8)\n",
    "for i in range(len_history):\n",
    "    my_motion_history.append(fMH1)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    # read a new frame from video\n",
    "    ret, frame = cap.read()\n",
    "    # if not successful, break loop\n",
    "    if not ret:\n",
    "        print(\"Cannot read a frame from video stream\")  \n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Original\", frame)\n",
    "\n",
    "    # ----------------\n",
    "    # b) Skin color detection\n",
    "    # ----------------\n",
    "    \n",
    "    frame_dst = my_skin_detect(frame)\n",
    "    cv2.imshow(\"Skin\", frame_dst)\n",
    "    \n",
    "    # ---------------\n",
    "    # c) hand gesture detection\n",
    "    # d) Graphical response upon detection\n",
    "    # ---------------\n",
    "    \n",
    "    match_template = gesture_matching(frame_dst, frame)\n",
    "    cv2.imshow(\"Frame\", match_template)\n",
    "\n",
    "    # wait for 'esc' key press for 30ms. If 'esc' key is pressed, break loop\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        print(\"esc key is pressed by user\")\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
